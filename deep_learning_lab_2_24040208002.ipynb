{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/narendra7959/Deep-Learning-Practicals/blob/main/deep_learning_lab_2_24040208002.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b175c35",
      "metadata": {
        "id": "4b175c35"
      },
      "source": [
        "## MDSC-302 | ASSIGNMENT-2 | 24040208002"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d938e0bb",
      "metadata": {
        "id": "d938e0bb"
      },
      "source": [
        "### Loading an image file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f72bb74",
      "metadata": {
        "id": "0f72bb74",
        "outputId": "aaebe131-a54d-41ab-f1bc-076ce547edb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: imageio in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (2.37.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from imageio) (2.2.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from imageio) (11.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install imageio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fc155a9",
      "metadata": {
        "id": "2fc155a9",
        "outputId": "93000da2-d137-46f4-8d07-000795d331f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(720, 1280, 3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import imageio.v2 as imageio\n",
        "img_arr = imageio.imread(r'dlwpt-code-master\\data\\p1ch4\\image-dog\\bobby.jpg')\n",
        "\n",
        "img_arr.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37f4be4f",
      "metadata": {
        "id": "37f4be4f"
      },
      "source": [
        "### Changing the layout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "976bbcb4",
      "metadata": {
        "id": "976bbcb4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "img = torch.from_numpy(img_arr)\n",
        "out = img.permute(2, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0efbd208",
      "metadata": {
        "id": "0efbd208"
      },
      "outputs": [],
      "source": [
        "batch_size = 3\n",
        "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)\n",
        "\n",
        "# This indicates that our batch will consist of three RGB images 256 pixels in height and 256 pixels in width\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f009eda",
      "metadata": {
        "id": "7f009eda"
      },
      "source": [
        "#### We can now load all PNG images from an input directory and store them in the tensor:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf9790fe",
      "metadata": {
        "id": "bf9790fe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "data_dir = r'D:\\MDSC-302(P)\\dlwpt-code-master\\data\\p1ch4\\image-cats'\n",
        "filenames = [name for name in os.listdir(data_dir)\n",
        "            if os.path.splitext(name)[-1] == '.png']\n",
        "for i, filename in enumerate(filenames):\n",
        "    img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
        "    img_t = torch.from_numpy(img_arr)\n",
        "    img_t = img_t.permute(2, 0, 1)\n",
        "    img_t = img_t[:3]\n",
        "    batch[i] = img_t"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "897f93c1",
      "metadata": {
        "id": "897f93c1"
      },
      "source": [
        "### Normalizing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17ab6988",
      "metadata": {
        "id": "17ab6988"
      },
      "outputs": [],
      "source": [
        "batch = batch.float()\n",
        "batch /= 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1fee3d5",
      "metadata": {
        "id": "d1fee3d5"
      },
      "source": [
        "#### Another possibility is to compute the mean and standard deviation of the input data and scale it so that the output has zero mean and unit standard deviation across each channel:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8496f50",
      "metadata": {
        "id": "e8496f50"
      },
      "outputs": [],
      "source": [
        "n_channels = batch.shape[1]\n",
        "for c in range(n_channels):\n",
        " mean = torch.mean(batch[:, c])\n",
        " std = torch.std(batch[:, c])\n",
        " batch[:, c] = (batch[:, c]- mean) / std\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "017a80df",
      "metadata": {
        "id": "017a80df"
      },
      "source": [
        "### Loading a Specialized Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71b97f83",
      "metadata": {
        "id": "71b97f83",
        "outputId": "e7592ab4-1fd4-4c1a-fd7b-5a8e3b39f4ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading DICOM (examining files): 1/99 files (1.0%21/99 files (21.2%26/99 files (26.3%66/99 files (66.7%99/99 files (100.0%)\n",
            "  Found 1 correct series.\n",
            "Reading DICOM (loading data): 33/99  (33.368/99  (68.799/99  (100.0%)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(99, 512, 512)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import imageio\n",
        "dir_path = r\"D:\\MDSC-302(P)\\dlwpt-code-master\\data\\p1ch4\\volumetric-dicom\\2-LUNG 3.0  B70f-04083\"\n",
        "vol_arr = imageio.volread(dir_path, 'DICOM')\n",
        "vol_arr.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9f4b993",
      "metadata": {
        "id": "e9f4b993"
      },
      "source": [
        "#### the layout is different from what PyTorch expects, due to having no channel information. So we’ll have to make room for the channel dimension using unsqueeze:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33889be4",
      "metadata": {
        "id": "33889be4",
        "outputId": "e89ded4d-e4cd-4659-e94e-12e6d6433aab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 99, 512, 512])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vol = torch.from_numpy(vol_arr).float()\n",
        "vol = torch.unsqueeze(vol, 0)\n",
        "\n",
        "vol.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e90ec729",
      "metadata": {
        "id": "e90ec729"
      },
      "source": [
        "### Representing Tabular Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2898b85a",
      "metadata": {
        "id": "2898b85a"
      },
      "source": [
        "#### Loading a Wine Data Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c65061b2",
      "metadata": {
        "id": "c65061b2",
        "outputId": "93bb6752-c03a-4b46-93de-a3ef63d01ce2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
              "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
              "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
              "       ...,\n",
              "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
              "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
              "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]],\n",
              "      shape=(4898, 12), dtype=float32)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "wine_path = r\"D:\\MDSC-302(P)\\dlwpt-code-master\\data\\p1ch4\\tabular-wine\\winequality-white.csv\"\n",
        "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\",skiprows=1)\n",
        "wineq_numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9aa876e",
      "metadata": {
        "id": "d9aa876e"
      },
      "source": [
        "#### Here we just prescribe what the type of the 2D array should be (32-bit floating-point), the delimiter used to separate values in each row, and the fact that the first line should not be read since it contains the column names\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecdfbc30",
      "metadata": {
        "id": "ecdfbc30",
        "outputId": "62b04577-2bfe-4975-e01e-63a4d5e5047e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4898, 12),\n",
              " ['fixed acidity',\n",
              "  'volatile acidity',\n",
              "  'citric acid',\n",
              "  'residual sugar',\n",
              "  'chlorides',\n",
              "  'free sulfur dioxide',\n",
              "  'total sulfur dioxide',\n",
              "  'density',\n",
              "  'pH',\n",
              "  'sulphates',\n",
              "  'alcohol',\n",
              "  'quality'])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "col_list = next(csv.reader(open(wine_path), delimiter=';'))\n",
        "wineq_numpy.shape, col_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73ffe21d",
      "metadata": {
        "id": "73ffe21d",
        "outputId": "8456c217-9cf6-45db-e8bc-1fe5cdd21944"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([4898, 12]), torch.float32)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wineq = torch.from_numpy(wineq_numpy)\n",
        "wineq.shape, wineq.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "179fbe90",
      "metadata": {
        "id": "179fbe90"
      },
      "source": [
        "### Representing Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a575fb7",
      "metadata": {
        "id": "1a575fb7",
        "outputId": "9415e9d7-862e-4f26-99d5-6d64db1be473"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
              "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
              "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
              "         ...,\n",
              "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
              "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
              "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
              " torch.Size([4898, 11]))"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = wineq[:, :-1]\n",
        "data, data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "818e75f5",
      "metadata": {
        "id": "818e75f5",
        "outputId": "c440cb4d-32ff-44e6-bd32-98492e65036e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([6., 6., 6.,  ..., 6., 7., 6.]), torch.Size([4898]))"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target = wineq[:,-1]\n",
        "target, target.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "742a4cde",
      "metadata": {
        "id": "742a4cde"
      },
      "source": [
        "#### If we want to transform the target tensor in a tensor of labels, we have two options, depending on the strategy or what we use the categorical data for. One is simply to treat labels as an integer vector of scores:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1c8c13f",
      "metadata": {
        "id": "e1c8c13f",
        "outputId": "6ba8a300-348c-4399-f839-c07511a8ba40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([6, 6, 6,  ..., 6, 7, 6])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target = wineq[:,-1].long()\n",
        "target"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79e36b3c",
      "metadata": {
        "id": "79e36b3c"
      },
      "source": [
        "#### One hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1b665c9",
      "metadata": {
        "id": "b1b665c9",
        "outputId": "a3ac4e23-509e-4cf5-d9d6-bf2f0a6d97b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_onehot = torch.zeros(target.shape[0], 10)\n",
        "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61d87887",
      "metadata": {
        "id": "61d87887",
        "outputId": "394fc735-ab60-4476-efb9-99801bcccef1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[6],\n",
              "        [6],\n",
              "        [6],\n",
              "        ...,\n",
              "        [6],\n",
              "        [7],\n",
              "        [6]])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_unsqueezed = target.unsqueeze(1)\n",
        "target_unsqueezed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae24cac0",
      "metadata": {
        "id": "ae24cac0"
      },
      "source": [
        "#### when to categerize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bda73f8",
      "metadata": {
        "id": "3bda73f8",
        "outputId": "62a08d91-abb9-4ce0-e44f-3e751e0ffb64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
              "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_mean = torch.mean(data, dim=0)\n",
        "data_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27dbb899",
      "metadata": {
        "id": "27dbb899",
        "outputId": "52d8dcd5-8223-421c-eec1-dee1b1dce679"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([7.1211e-01, 1.0160e-02, 1.4646e-02, 2.5726e+01, 4.7733e-04, 2.8924e+02,\n",
              "        1.8061e+03, 8.9455e-06, 2.2801e-02, 1.3025e-02, 1.5144e+00])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_var = torch.var(data, dim=0)\n",
        "data_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e59a88b6",
      "metadata": {
        "id": "e59a88b6",
        "outputId": "8fa3a2c2-9bdf-4a17-a635-7931a7b1adb7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.7208e-01, -8.1761e-02,  2.1326e-01,  ..., -1.2468e+00,\n",
              "         -3.4915e-01, -1.3930e+00],\n",
              "        [-6.5743e-01,  2.1587e-01,  4.7996e-02,  ...,  7.3995e-01,\n",
              "          1.3422e-03, -8.2419e-01],\n",
              "        [ 1.4756e+00,  1.7450e-02,  5.4378e-01,  ...,  4.7505e-01,\n",
              "         -4.3677e-01, -3.3663e-01],\n",
              "        ...,\n",
              "        [-4.2043e-01, -3.7940e-01, -1.1915e+00,  ..., -1.3130e+00,\n",
              "         -2.6153e-01, -9.0545e-01],\n",
              "        [-1.6054e+00,  1.1666e-01, -2.8253e-01,  ...,  1.0049e+00,\n",
              "         -9.6251e-01,  1.8574e+00],\n",
              "        [-1.0129e+00, -6.7703e-01,  3.7852e-01,  ...,  4.7505e-01,\n",
              "         -1.4882e+00,  1.0448e+00]])"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_normalized = (data- data_mean) / torch.sqrt(data_var)\n",
        "data_normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2977a2f",
      "metadata": {
        "id": "d2977a2f"
      },
      "source": [
        "#### finding thresholds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efbdbd49",
      "metadata": {
        "id": "efbdbd49"
      },
      "source": [
        "PyTorch also provides comparison functions,\n",
        "here torch.le(target, 3), but using operators\n",
        "seems to be a good standard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "908f5a93",
      "metadata": {
        "id": "908f5a93",
        "outputId": "8360bcea-89f7-45ce-82d1-b86aaef7c5b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([4898]), torch.bool, tensor(20))"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bad_indexes = target <= 3\n",
        "bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7bbde8b",
      "metadata": {
        "id": "f7bbde8b"
      },
      "source": [
        "The bad_indexes tensor has the same shape\n",
        "as target, with values of False or True depending on the outcome of the comparison\n",
        "between our threshold and each element in the original target tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05091265",
      "metadata": {
        "id": "05091265",
        "outputId": "2d8021f9-856c-4af0-fbc2-4e0b65e264ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 11])"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bad_data = data[bad_indexes]\n",
        "bad_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef1c2871",
      "metadata": {
        "id": "ef1c2871"
      },
      "source": [
        "For Boolean NumPy arrays and PyTorch tensors, the & operator does a logical “and” operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1d500bb",
      "metadata": {
        "id": "d1d500bb",
        "outputId": "5e2a927d-e2f0-4a6e-87b4-f95d1175d575"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 0 fixed acidity          7.60   6.89   6.73\n",
            " 1 volatile acidity       0.33   0.28   0.27\n",
            " 2 citric acid            0.34   0.34   0.33\n",
            " 3 residual sugar         6.39   6.71   5.26\n",
            " 4 chlorides              0.05   0.05   0.04\n",
            " 5 free sulfur dioxide   53.33  35.42  34.55\n",
            " 6 total sulfur dioxide 170.60 141.83 125.25\n",
            " 7 density                0.99   0.99   0.99\n",
            " 8 pH                     3.19   3.18   3.22\n",
            " 9 sulphates              0.47   0.49   0.50\n",
            "10 alcohol               10.34  10.26  11.42\n"
          ]
        }
      ],
      "source": [
        "bad_data = data[target <= 3]\n",
        "mid_data = data[(target > 3) & (target < 7)]\n",
        "good_data = data[target >= 7]\n",
        "\n",
        "bad_mean = torch.mean(bad_data, dim=0)\n",
        "mid_mean = torch.mean(mid_data, dim=0)\n",
        "good_mean = torch.mean(good_data, dim=0)\n",
        "\n",
        "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):\n",
        "    print('{:2} {:20} {:6.2f} {:6.2f} {:6.2f}'.format(i, *args))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea2a71dc",
      "metadata": {
        "id": "ea2a71dc"
      },
      "source": [
        "Let’s get the indexes where the total sulfur dioxide column is below the midpoint we\n",
        "calculated earlier, like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a80cb865",
      "metadata": {
        "id": "a80cb865",
        "outputId": "423be0ad-bea4-4778-b74c-b5ef8a7569d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([4898]), torch.bool, tensor(2727))"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_sulfur_threshold = 141.83\n",
        "total_sulfur_data = data[:,6]\n",
        "predicted_indexes = torch.lt(total_sulfur_data, total_sulfur_threshold)\n",
        "\n",
        "predicted_indexes.shape, predicted_indexes.dtype, predicted_indexes.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b580117",
      "metadata": {
        "id": "7b580117"
      },
      "source": [
        "This means our threshold implies that just over half of all the wines are going to be\n",
        "high quality. Next, we’ll need to get the indexes of the actually good wines:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bba9a6ac",
      "metadata": {
        "id": "bba9a6ac",
        "outputId": "c6cd772b-8c78-4f12-fb46-91e12fd4759c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([4898]), torch.bool, tensor(3258))"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "actual_indexes = target > 5\n",
        "actual_indexes.shape, actual_indexes.dtype, actual_indexes.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6885b76e",
      "metadata": {
        "id": "6885b76e"
      },
      "source": [
        "We will perform a logical “and” between our\n",
        "prediction indexes and the actual good indexes (remember that each is just an array\n",
        "of zeros and ones) and use that intersection of wines-in-agreement to determine how\n",
        "well we did:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70e58ae2",
      "metadata": {
        "id": "70e58ae2",
        "outputId": "21643a56-3856-48dd-d398-ed59422cfafa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2018, 0.74000733406674, 0.6193984039287906)"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_matches = torch.sum(actual_indexes & predicted_indexes).item()\n",
        "n_predicted = torch.sum(predicted_indexes).item()\n",
        "n_actual = torch.sum(actual_indexes).item()\n",
        "n_matches, n_matches / n_predicted, n_matches / n_actual"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db4d6bb1",
      "metadata": {
        "id": "db4d6bb1"
      },
      "source": [
        "### working with time series"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae49e50c",
      "metadata": {
        "id": "ae49e50c"
      },
      "source": [
        "#### adding a time dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1a8c550",
      "metadata": {
        "id": "d1a8c550",
        "outputId": "e546abba-09ae-48b8-e067-e938fb25a1bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 3.0000e+00, 1.3000e+01,\n",
              "         1.6000e+01],\n",
              "        [2.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 8.0000e+00, 3.2000e+01,\n",
              "         4.0000e+01],\n",
              "        [3.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 5.0000e+00, 2.7000e+01,\n",
              "         3.2000e+01],\n",
              "        ...,\n",
              "        [1.7377e+04, 3.1000e+01, 1.0000e+00,  ..., 7.0000e+00, 8.3000e+01,\n",
              "         9.0000e+01],\n",
              "        [1.7378e+04, 3.1000e+01, 1.0000e+00,  ..., 1.3000e+01, 4.8000e+01,\n",
              "         6.1000e+01],\n",
              "        [1.7379e+04, 3.1000e+01, 1.0000e+00,  ..., 1.2000e+01, 3.7000e+01,\n",
              "         4.9000e+01]])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bikes_numpy = np.loadtxt(\n",
        "r\"D:\\MDSC-302(P)\\dlwpt-code-master\\data\\p1ch4\\bike-sharing-dataset\\hour-fixed.csv\",\n",
        "dtype=np.float32,\n",
        "delimiter=\",\",\n",
        "skiprows=1,\n",
        "converters={1: lambda x: float(x[8:10])})\n",
        "bikes = torch.from_numpy(bikes_numpy)\n",
        "bikes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb1339e6",
      "metadata": {
        "id": "fb1339e6"
      },
      "source": [
        "### Shaping data by time period"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeb8c082",
      "metadata": {
        "id": "aeb8c082"
      },
      "source": [
        "We might want to break up the two-year dataset into wider observation periods, like\n",
        "days. This way we’ll have N (for number of samples) collections of C sequences of length\n",
        "L. In other words, our time series dataset would be a tensor of dimension 3 and shape\n",
        "N × C × L. The C would remain our 17 channels, while L would be 24: 1 per hour of\n",
        "the day."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ec13720",
      "metadata": {
        "id": "2ec13720",
        "outputId": "60836b5d-63df-4358-ae09-f6f8eb84cb1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([17520, 17]), (17, 1))"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bikes.shape, bikes.stride()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56aca4ee",
      "metadata": {
        "id": "56aca4ee"
      },
      "source": [
        "That’s 17,520 hours, 17 columns. Now let’s reshape the data to have 3 axes—day, hour,\n",
        "and then our 17 columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3b8bd7b",
      "metadata": {
        "id": "d3b8bd7b",
        "outputId": "7e56df62-ac71-4914-c6fb-560cc9ba70fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([730, 24, 17]), (408, 17, 1))"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "daily_bikes = bikes.view(-1, 24, bikes.shape[1])\n",
        "daily_bikes.shape, daily_bikes.stride()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e1c159f",
      "metadata": {
        "id": "6e1c159f"
      },
      "source": [
        "We see that the rightmost dimension is the number of columns in the original\n",
        "dataset. Then, in the middle dimension, we have time, split into chunks of 24 sequential\n",
        "hours. In other words, we now have N sequences of L hours in a day, for C channels.\n",
        "To get to our desired N × C × L ordering, we need to transpose the tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80feef06",
      "metadata": {
        "id": "80feef06",
        "outputId": "97959ab8-3272-45bd-b8fa-2c73ccbd08f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([730, 17, 24]), (408, 1, 17))"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "daily_bikes = daily_bikes.transpose(1, 2)\n",
        "daily_bikes.shape, daily_bikes.stride()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ed486b9",
      "metadata": {
        "id": "7ed486b9"
      },
      "source": [
        "### Ready for training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4038fe8",
      "metadata": {
        "id": "d4038fe8"
      },
      "source": [
        "In order to make it easier to render our data, we’re going to limit ourselves to the\n",
        "first day for a moment. We initialize a zero-filled matrix with a number of rows equal\n",
        "to the number of hours in the day and number of columns equal to the number of\n",
        "weather levels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adbb565f",
      "metadata": {
        "id": "adbb565f",
        "outputId": "7219b8fa-eb92-42f1-d5c8-249af65ff053"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2])"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_day = bikes[:24].long()\n",
        "weather_onehot = torch.zeros(first_day.shape[0], 4)\n",
        "first_day[:,9]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "503fd7dd",
      "metadata": {
        "id": "503fd7dd"
      },
      "source": [
        "Then we scatter ones into our matrix according to the corresponding level at each\n",
        "row. Remember the use of unsqueeze to add a singleton dimension as we did in the\n",
        "previous sections:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b54b5d78",
      "metadata": {
        "id": "b54b5d78",
        "outputId": "b4e78fde-4bb9-4542-9b66-6a634b67b93a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.]])"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weather_onehot.scatter_(\n",
        "dim=1,\n",
        "index=first_day[:,9].unsqueeze(1).long()- 1,\n",
        "value=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4bcf57f",
      "metadata": {
        "id": "f4bcf57f"
      },
      "source": [
        "Last, we concatenate our matrix to our original dataset using the cat function.\n",
        "Let’s look at the first of our results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7612123a",
      "metadata": {
        "id": "7612123a",
        "outputId": "a791e52e-cdf6-4333-c333-1223f263b359"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.0000,  1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  6.0000,\n",
              "          0.0000,  1.0000,  0.2400,  0.2879,  0.8100,  0.0000,  3.0000, 13.0000,\n",
              "         16.0000,  1.0000,  0.0000,  0.0000,  0.0000]])"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cat((bikes[:24], weather_onehot), 1)[:1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "381137e0",
      "metadata": {
        "id": "381137e0"
      },
      "source": [
        "We could have done the same with the reshaped daily_bikes tensor. Remember\n",
        "that it is shaped (B, C, L), where L = 24. We first create the zero tensor, with the same\n",
        "B and L, but with the number of additional columns as C:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7b38b6d",
      "metadata": {
        "id": "d7b38b6d",
        "outputId": "b4d1f414-cbdc-44fb-87c6-08abe830d6da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([730, 4, 24])"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "daily_weather_onehot = torch.zeros(daily_bikes.shape[0], 4,\n",
        "daily_bikes.shape[2])\n",
        "daily_weather_onehot.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a455b91",
      "metadata": {
        "id": "9a455b91"
      },
      "source": [
        "Then we scatter the one-hot encoding into the tensor in the C dimension. Since this\n",
        "operation is performed in place, only the content of the tensor will change:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33797f5e",
      "metadata": {
        "id": "33797f5e",
        "outputId": "8873d415-6364-44a9-eae1-314748a760c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([730, 4, 24])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "daily_weather_onehot.scatter_(\n",
        "1, daily_bikes[:,9,:].long().unsqueeze(1)- 1, 1.0)\n",
        "daily_weather_onehot.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85c55296",
      "metadata": {
        "id": "85c55296"
      },
      "outputs": [],
      "source": [
        "daily_bikes = torch.cat((daily_bikes, daily_weather_onehot), dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e44aebba",
      "metadata": {
        "id": "e44aebba"
      },
      "outputs": [],
      "source": [
        "daily_bikes[:, 9, :] = (daily_bikes[:, 9, :]- 1.0) / 3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c048525d",
      "metadata": {
        "id": "c048525d"
      },
      "outputs": [],
      "source": [
        "temp = daily_bikes[:, 10, :]\n",
        "temp_min = torch.min(temp)\n",
        "temp_max = torch.max(temp)\n",
        "daily_bikes[:, 10, :] = ((daily_bikes[:, 10, :]- temp_min)\n",
        "/ (temp_max- temp_min))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c590802",
      "metadata": {
        "id": "3c590802"
      },
      "outputs": [],
      "source": [
        "temp = daily_bikes[:, 10, :]\n",
        "daily_bikes[:, 10, :] = ((daily_bikes[:, 10, :]- torch.mean(temp))\n",
        "/ torch.std(temp))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "045c1885",
      "metadata": {
        "id": "045c1885"
      },
      "source": [
        "### Representing Text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fe4252e",
      "metadata": {
        "id": "0fe4252e"
      },
      "source": [
        "#### Converting text to numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "803c7514",
      "metadata": {
        "id": "803c7514"
      },
      "outputs": [],
      "source": [
        "with open(r'D:\\MDSC-302(P)\\dlwpt-code-master\\data\\p1ch4\\jane-austen\\1342-0.txt', encoding='utf8') as f:\n",
        " text = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1308d1e3",
      "metadata": {
        "id": "1308d1e3"
      },
      "source": [
        "##### one hot encoding characters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fc31099",
      "metadata": {
        "id": "6fc31099"
      },
      "source": [
        "#### We first split our text into a list of lines and pick an arbitrary line to focus on:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4f27151",
      "metadata": {
        "id": "f4f27151",
        "outputId": "5979e2ca-bc6b-47f2-fa37-b334b14b8f21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'“Impossible, Mr. Bennet, impossible, when I am not acquainted with him'"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines = text.split('\\n')\n",
        "line = lines[200]\n",
        "line"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7f25bc6",
      "metadata": {
        "id": "b7f25bc6"
      },
      "source": [
        "#### Let’s create a tensor that can hold the total number of one-hot-encoded characters for the whole line:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ec77d1d",
      "metadata": {
        "id": "8ec77d1d",
        "outputId": "35c69b1d-c7d0-4dc0-c1bb-7093fe3e8c83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([70, 128])"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "letter_t = torch.zeros(len(line), 128)\n",
        "letter_t.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2652c1b9",
      "metadata": {
        "id": "2652c1b9"
      },
      "source": [
        "#### The index where the one has to be set corresponds to the index of the character in the encoding:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c03739d",
      "metadata": {
        "id": "1c03739d"
      },
      "outputs": [],
      "source": [
        "for i, letter in enumerate(line.lower().strip()):\n",
        "    letter_index = ord(letter) if ord(letter) < 128 else 0\n",
        "    letter_t[i][letter_index] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73b34eb0",
      "metadata": {
        "id": "73b34eb0"
      },
      "source": [
        "#### One Hot encoding whole words"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a78125c3",
      "metadata": {
        "id": "a78125c3"
      },
      "source": [
        "#### We’ll define clean_words, which takes text and returns it in lowercase and stripped of punctuation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9e7e0b5",
      "metadata": {
        "id": "f9e7e0b5",
        "outputId": "0809d0bf-2a08-4311-e013-99c4e190edd3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('“Impossible, Mr. Bennet, impossible, when I am not acquainted with him',\n",
              " ['impossible',\n",
              "  'mr',\n",
              "  'bennet',\n",
              "  'impossible',\n",
              "  'when',\n",
              "  'i',\n",
              "  'am',\n",
              "  'not',\n",
              "  'acquainted',\n",
              "  'with',\n",
              "  'him'])"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def clean_words(input_str):\n",
        "    punctuation = '.,;:\"!?”“_-'\n",
        "    word_list = input_str.lower().replace('\\n',' ').split()\n",
        "    word_list = [word.strip(punctuation) for word in word_list]\n",
        "    return word_list\n",
        "\n",
        "words_in_line = clean_words(line)\n",
        "line, words_in_line"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68483d1b",
      "metadata": {
        "id": "68483d1b"
      },
      "source": [
        "#### Next, let’s build a mapping of words to indexes in our encoding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02eed866",
      "metadata": {
        "id": "02eed866",
        "outputId": "aa24cb1c-29c3-4449-d5a3-154cf073d4b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7261, 3394)"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_list = sorted(set(clean_words(text)))\n",
        "word2index_dict = {word: i for (i, word) in enumerate(word_list)}\n",
        "len(word2index_dict), word2index_dict['impossible']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31a571ec",
      "metadata": {
        "id": "31a571ec"
      },
      "source": [
        "####  We create an empty vector and assign the one-hot-encoded values of the word in the sentence:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3de3b21d",
      "metadata": {
        "id": "3de3b21d",
        "outputId": "7b38b410-635d-434f-9362-974db8fbd15e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 0 3394 impossible\n",
            " 1 4305 mr\n",
            " 2  813 bennet\n",
            " 3 3394 impossible\n",
            " 4 7078 when\n",
            " 5 3315 i\n",
            " 6  415 am\n",
            " 7 4436 not\n",
            " 8  239 acquainted\n",
            " 9 7148 with\n",
            "10 3215 him\n",
            "torch.Size([11, 7261])\n"
          ]
        }
      ],
      "source": [
        "word_t = torch.zeros(len(words_in_line), len(word2index_dict))\n",
        "for i, word in enumerate(words_in_line):\n",
        "    word_index = word2index_dict[word]\n",
        "    word_t[i][word_index] = 1\n",
        "    print('{:2} {:4} {}'.format(i, word_index, word))\n",
        "\n",
        "print(word_t.shape)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}